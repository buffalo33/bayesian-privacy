{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import project and set a symbolic link in /content\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# set up mount symlink\n",
        "\n",
        "DRIVE_PATH = '/content/gdrive/My\\ Drive/bayesian-privacy'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## the space in `My Drive` causes some issues,\n",
        "## make a symlink to avoid this\n",
        "SYM_PATH = '/content/bayesian-privacy'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH\n",
        "\n",
        "## Move in the project directory\n",
        "%cd /content/bayesian-privacy\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R3mt05exlux",
        "outputId": "fd06292f-ab40-4d23-b5ef-b568d4f7bf6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/bayesian-differential-privacy-master\n",
            "/content/gdrive/My Drive/bayesian-differential-privacy-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkrzRM0nxk-O"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FcfwL9bxk-S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from torch.optim.optimizer import required\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "\n",
        "from bayesian_privacy_accountant import BayesianPrivacyAccountant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ5mo3Gixk-T",
        "outputId": "ab7ec280-6c18-4f69-81aa-b720a207a972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA: gpu_id = 0\n",
            "Random Seed:  8664\n"
          ]
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--dataset', default='mnist', help='mnist | cifar10 | svhn')\n",
        "parser.add_argument('--dataroot', default='data', help='path to dataset')\n",
        "parser.add_argument('--batchSize', type=int, default=1024, help='input batch size')\n",
        "parser.add_argument('--imageSize', type=int, default=28, help='the height / width of the input image to network')\n",
        "parser.add_argument('--nClasses', type=int, default=10, help='number of labels (classes)')\n",
        "parser.add_argument('--nChannels', type=int, default=1, help='number of colour channels')\n",
        "parser.add_argument('--ndf', type=int, default=64, help='number of filters in CNN')\n",
        "parser.add_argument('--n_epochs', type=int, default=32, help='number of epochs to train for')\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='learning rate, default=0.0002')\n",
        "parser.add_argument('--C', type=float, default=1.0, help='embedding L2-norm bound, default=1.0')\n",
        "parser.add_argument('--sigma', type=float, default=0.1, help='noise variance, default=0.5')\n",
        "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
        "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
        "parser.add_argument('--outf', default='output', help='folder to output images and model checkpoints')\n",
        "parser.add_argument('--manualSeed', type=int, default=8664, help='manual seed for reproducibility')\n",
        "\n",
        "opt, unknown = parser.parse_known_args()\n",
        "\n",
        "try:\n",
        "    os.makedirs(opt.outf)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    opt.cuda = True\n",
        "    opt.ngpu = 1\n",
        "    gpu_id = torch.cuda.current_device()\n",
        "    print(\"Using CUDA: gpu_id = %d\" % gpu_id)\n",
        "    \n",
        "if opt.manualSeed is None:\n",
        "    opt.manualSeed = random.randint(1, 10000)\n",
        "print(\"Random Seed: \", opt.manualSeed)\n",
        "random.seed(opt.manualSeed)\n",
        "torch.manual_seed(opt.manualSeed)\n",
        "if opt.cuda:\n",
        "    torch.cuda.manual_seed_all(opt.manualSeed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f550dGAjxk-U"
      },
      "outputs": [],
      "source": [
        "class View(nn.Module):\n",
        "    \"\"\"\n",
        "        Implements a reshaping module.\n",
        "        Allows to reshape a tensor between NN layers.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, *shape):\n",
        "        super(View, self).__init__()\n",
        "        self.shape = shape\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return input.view(self.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj9zxAe8xk-U"
      },
      "outputs": [],
      "source": [
        "filterSize = 5\n",
        "w_out = 4\n",
        "h_out = 4\n",
        "\n",
        "class SimpleConvNet(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(opt.nChannels, opt.ndf, filterSize),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.BatchNorm2d(opt.ndf),\n",
        "            nn.Conv2d(opt.ndf, opt.ndf, filterSize),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(opt.ndf),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            View(-1, opt.ndf * w_out * h_out),\n",
        "            #PrintLayer(\"View\"),\n",
        "            #View(-1, 784),\n",
        "            nn.Linear(opt.ndf * w_out * h_out, 384),\n",
        "            nn.SELU(inplace=True),\n",
        "            nn.Linear(384, 192),\n",
        "            nn.SELU(inplace=True),\n",
        "            nn.Linear(192, opt.nClasses),\n",
        "            #nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "72BDdBPmxk-V"
      },
      "outputs": [],
      "source": [
        "def test(testloader, net):\n",
        "    \"\"\"\n",
        "        Compute test accuracy.\n",
        "    \"\"\"\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    '''\n",
        "    if opt.cuda:\n",
        "        net = net.cuda()\n",
        "    '''\n",
        "    \n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        \n",
        "        if opt.cuda:\n",
        "            images = images.cuda(gpu_id)\n",
        "            labels = labels.cuda(gpu_id)\n",
        "            \n",
        "        outputs = net(Variable(images))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted.cpu().numpy())\n",
        "        #print(labels.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == (labels.long().view(-1) % 10)).sum()\n",
        "        #print torch.cat([predicted.view(-1, 1), (labels.long() % 10)], dim=1)\n",
        "\n",
        "    print('Accuracy of the network on test images: %f %%' % (100 * float(correct) / total))\n",
        "    return 100 * float(correct) / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgbJwR1jxk-W"
      },
      "outputs": [],
      "source": [
        "def sparsify_update(params, p, use_grad_field=True):\n",
        "    init = True\n",
        "    for param in params:\n",
        "        if param is not None:\n",
        "            if init:\n",
        "                idx = torch.zeros_like(param, dtype=torch.bool)\n",
        "                idx.bernoulli_(1 - p)\n",
        "            if use_grad_field:\n",
        "                if param.grad is not None:\n",
        "                    idx = torch.zeros_like(param, dtype=torch.bool)\n",
        "                    idx.bernoulli_(1 - p)\n",
        "                    param.grad.data[idx] = 0\n",
        "            else:\n",
        "                init = False\n",
        "                param.data[idx] = 0\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbU5mj3Bxk-W"
      },
      "outputs": [],
      "source": [
        "def train(trainloader, student, n_epochs=25, lr=0.0001, accountant=None):\n",
        "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    #optimizer = optim.Adam(student.parameters(), lr=lr)\n",
        "    optimizer = optim.SGD(student.parameters(), lr=lr)\n",
        "    \n",
        "    if opt.cuda:\n",
        "        student = student.cuda(gpu_id)\n",
        "        criterion = criterion.cuda(gpu_id)\n",
        "    \n",
        "    accuracies = []\n",
        "    \n",
        "    num_batches = len(trainloader.dataset) / opt.batchSize + 1\n",
        "    sampling_prob = 0.1\n",
        "    max_grad_norm = opt.C\n",
        "    \n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            \n",
        "            if opt.cuda:\n",
        "                inputs = inputs.cuda(gpu_id)\n",
        "                labels = labels.cuda(gpu_id)\n",
        "            \n",
        "            inputv = Variable(inputs)\n",
        "            labelv = Variable(labels.long().view(-1) % 10)\n",
        "            \n",
        "            batch_size = float(len(inputs))\n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # forward + backward + optimize\n",
        "            outputs = student(inputv)\n",
        "            loss = criterion(outputs, labelv)\n",
        "            \n",
        "            #max_grad_norm = opt.C * 0.9**epoch\n",
        "            if accountant:\n",
        "                grads_est = []\n",
        "                num_subbatch = 8\n",
        "                for j in range(num_subbatch):\n",
        "                    grad_sample = torch.autograd.grad(\n",
        "                        loss[np.delete(range(int(batch_size)), j)].mean(), \n",
        "                        [p for p in student.parameters() if p.requires_grad], \n",
        "                        retain_graph=True\n",
        "                    )\n",
        "                    with torch.no_grad():\n",
        "                        grad_sample = torch.cat([g.view(-1) for g in grad_sample])\n",
        "                        grad_sample /= max(1.0, grad_sample.norm().item() / max_grad_norm)\n",
        "                        grads_est += [grad_sample]\n",
        "                with torch.no_grad():\n",
        "                    grads_est = torch.stack(grads_est)\n",
        "                    sparsify_update(grads_est, p=sampling_prob, use_grad_field=False)\n",
        "                \n",
        "            (loss.mean()).backward()\n",
        "            running_loss += loss.mean().item()\n",
        "            \n",
        "            if accountant:\n",
        "                with torch.no_grad():\n",
        "                    torch.nn.utils.clip_grad_norm_(student.parameters(), max_grad_norm)\n",
        "                    for group in optimizer.param_groups:\n",
        "                        for p in group['params']:\n",
        "                            if p.grad is not None:\n",
        "                                p.grad += torch.randn_like(p.grad) * (opt.sigma * max_grad_norm)\n",
        "                    sparsify_update(student.parameters(), p=sampling_prob)\n",
        "                \n",
        "            optimizer.step()\n",
        "            \n",
        "            if accountant:\n",
        "                with torch.no_grad():\n",
        "                    batch_size = float(len(inputs))\n",
        "                    q = batch_size / len(trainloader.dataset)\n",
        "                    # NOTE: \n",
        "                    # Using combinations within a set of gradients (like below)\n",
        "                    # does not actually produce samples from the correct distribution\n",
        "                    # (for that, we need to sample pairs of gradients independently).\n",
        "                    # However, the difference is not significant, and it speeds up computations.\n",
        "                    pairs = list(zip(*itertools.combinations(grads_est, 2)))\n",
        "                    accountant.accumulate(\n",
        "                        ldistr=(torch.stack(pairs[0]), opt.sigma*max_grad_norm),\n",
        "                        rdistr=(torch.stack(pairs[1]), opt.sigma*max_grad_norm),\n",
        "                        q=q, \n",
        "                        steps=1,\n",
        "                    )\n",
        "            \n",
        "        # print training stats every epoch\n",
        "        running_eps = accountant.get_privacy(target_delta=1e-5) if accountant else None\n",
        "        print(\"Epoch: %d/%d. Loss: %.3f. Privacy (𝜀,𝛿): %s\" %\n",
        "              (epoch + 1, n_epochs, running_loss / len(trainloader), running_eps))\n",
        "                \n",
        "        acc = test(testloader, student)\n",
        "        accuracies += [acc]\n",
        "        print(\"Test accuracy is %d %%\" % acc)\n",
        "\n",
        "    print('Finished Training')\n",
        "    return student.cpu(), accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBJ-bmSixk-Y"
      },
      "outputs": [],
      "source": [
        "# transformations applied to data\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# switch datasets\n",
        "if opt.dataset == 'mnist':\n",
        "    trainset = torchvision.datasets.MNIST(root=opt.dataroot + os.sep + opt.dataset, train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.MNIST(root=opt.dataroot + os.sep + opt.dataset, train=False, download=True, transform=transform)\n",
        "elif opt.dataset == 'cifar10':\n",
        "    trainset = torchvision.datasets.CIFAR10(root=opt.dataroot + os.sep + opt.dataset, train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=opt.dataroot + os.sep + opt.dataset, train=False, download=True, transform=transform)\n",
        "elif opt.dataset == 'svhn':\n",
        "    trainset = torchvision.datasets.SVHN(root=opt.dataroot + os.sep + opt.dataset, split='train', download=True, transform=transform)\n",
        "    testset = torchvision.datasets.SVHN(root=opt.dataroot + os.sep + opt.dataset, split='test', download=True, transform=transform)\n",
        "\n",
        "#val_size = 10000\n",
        "#valset = torch.utils.data.Subset(trainset, range(val_size))\n",
        "#trainset = torch.utils.data.Subset(trainset, range(val_size, len(trainset)))\n",
        "    \n",
        "# initialise data loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=opt.batchSize, shuffle=True, num_workers=2, drop_last=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=opt.batchSize, shuffle=True, num_workers=2)\n",
        "\n",
        "# names of classes\n",
        "classes = tuple(np.arange(10).astype(str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM5PNJytxk-Y",
        "outputId": "8a83133f-96cf-4612-fb8d-6a2a230d2072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/32. Loss: 2.153. Privacy (𝜀,𝛿): (0.3603139622317727, 1e-05)\n",
            "Accuracy of the network on test images: 46.720000 %\n",
            "Test accuracy is 46 %\n",
            "Epoch: 2/32. Loss: 1.797. Privacy (𝜀,𝛿): (0.36099711163368264, 1e-05)\n",
            "Accuracy of the network on test images: 70.270000 %\n",
            "Test accuracy is 70 %\n",
            "Epoch: 3/32. Loss: 1.511. Privacy (𝜀,𝛿): (0.3618431923277266, 1e-05)\n",
            "Accuracy of the network on test images: 78.320000 %\n",
            "Test accuracy is 78 %\n",
            "Epoch: 4/32. Loss: 1.286. Privacy (𝜀,𝛿): (0.36288609873518374, 1e-05)\n",
            "Accuracy of the network on test images: 83.190000 %\n",
            "Test accuracy is 83 %\n",
            "Epoch: 5/32. Loss: 1.094. Privacy (𝜀,𝛿): (0.3641397125430758, 1e-05)\n",
            "Accuracy of the network on test images: 85.650000 %\n",
            "Test accuracy is 85 %\n",
            "Epoch: 6/32. Loss: 0.921. Privacy (𝜀,𝛿): (0.3655912125048158, 1e-05)\n",
            "Accuracy of the network on test images: 88.030000 %\n",
            "Test accuracy is 88 %\n",
            "Epoch: 7/32. Loss: 0.775. Privacy (𝜀,𝛿): (0.36756126237951814, 1e-05)\n",
            "Accuracy of the network on test images: 89.390000 %\n",
            "Test accuracy is 89 %\n",
            "Epoch: 8/32. Loss: 0.654. Privacy (𝜀,𝛿): (0.3699454028587821, 1e-05)\n",
            "Accuracy of the network on test images: 90.480000 %\n",
            "Test accuracy is 90 %\n",
            "Epoch: 9/32. Loss: 0.554. Privacy (𝜀,𝛿): (0.3733591843513721, 1e-05)\n",
            "Accuracy of the network on test images: 91.440000 %\n",
            "Test accuracy is 91 %\n",
            "Epoch: 10/32. Loss: 0.470. Privacy (𝜀,𝛿): (0.3773823137758222, 1e-05)\n",
            "Accuracy of the network on test images: 92.310000 %\n",
            "Test accuracy is 92 %\n",
            "Epoch: 11/32. Loss: 0.406. Privacy (𝜀,𝛿): (0.3825275183677642, 1e-05)\n",
            "Accuracy of the network on test images: 93.150000 %\n",
            "Test accuracy is 93 %\n",
            "Epoch: 12/32. Loss: 0.362. Privacy (𝜀,𝛿): (0.3889318364611675, 1e-05)\n",
            "Accuracy of the network on test images: 93.710000 %\n",
            "Test accuracy is 93 %\n",
            "Epoch: 13/32. Loss: 0.329. Privacy (𝜀,𝛿): (0.3949056657833584, 1e-05)\n",
            "Accuracy of the network on test images: 94.090000 %\n",
            "Test accuracy is 94 %\n",
            "Epoch: 14/32. Loss: 0.306. Privacy (𝜀,𝛿): (0.4006768231916834, 1e-05)\n",
            "Accuracy of the network on test images: 94.350000 %\n",
            "Test accuracy is 94 %\n",
            "Epoch: 15/32. Loss: 0.286. Privacy (𝜀,𝛿): (0.40651619872923034, 1e-05)\n",
            "Accuracy of the network on test images: 94.460000 %\n",
            "Test accuracy is 94 %\n",
            "Epoch: 16/32. Loss: 0.269. Privacy (𝜀,𝛿): (0.41296610536681344, 1e-05)\n",
            "Accuracy of the network on test images: 94.600000 %\n",
            "Test accuracy is 94 %\n",
            "Epoch: 17/32. Loss: 0.256. Privacy (𝜀,𝛿): (0.41747012200009304, 1e-05)\n",
            "Accuracy of the network on test images: 94.940000 %\n",
            "Test accuracy is 94 %\n",
            "Epoch: 18/32. Loss: 0.245. Privacy (𝜀,𝛿): (0.42262291737793456, 1e-05)\n",
            "Accuracy of the network on test images: 94.850000 %\n",
            "Test accuracy is 94 %\n",
            "Epoch: 19/32. Loss: 0.236. Privacy (𝜀,𝛿): (0.4299284430205341, 1e-05)\n",
            "Accuracy of the network on test images: 94.880000 %\n",
            "Test accuracy is 94 %\n",
            "Epoch: 20/32. Loss: 0.227. Privacy (𝜀,𝛿): (0.43563916715200124, 1e-05)\n",
            "Accuracy of the network on test images: 95.270000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 21/32. Loss: 0.218. Privacy (𝜀,𝛿): (0.4411098659229539, 1e-05)\n",
            "Accuracy of the network on test images: 95.300000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 22/32. Loss: 0.212. Privacy (𝜀,𝛿): (0.4496939744208293, 1e-05)\n",
            "Accuracy of the network on test images: 95.240000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 23/32. Loss: 0.206. Privacy (𝜀,𝛿): (0.4555379596495739, 1e-05)\n",
            "Accuracy of the network on test images: 95.350000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 24/32. Loss: 0.202. Privacy (𝜀,𝛿): (0.46212029069187666, 1e-05)\n",
            "Accuracy of the network on test images: 95.590000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 25/32. Loss: 0.195. Privacy (𝜀,𝛿): (0.46928737764984285, 1e-05)\n",
            "Accuracy of the network on test images: 95.810000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 26/32. Loss: 0.189. Privacy (𝜀,𝛿): (0.47582339336312257, 1e-05)\n",
            "Accuracy of the network on test images: 95.870000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 27/32. Loss: 0.185. Privacy (𝜀,𝛿): (0.4837855559832063, 1e-05)\n",
            "Accuracy of the network on test images: 95.870000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 28/32. Loss: 0.179. Privacy (𝜀,𝛿): (0.49151671235053374, 1e-05)\n",
            "Accuracy of the network on test images: 95.980000 %\n",
            "Test accuracy is 95 %\n",
            "Epoch: 29/32. Loss: 0.171. Privacy (𝜀,𝛿): (0.497546850292618, 1e-05)\n",
            "Accuracy of the network on test images: 96.020000 %\n",
            "Test accuracy is 96 %\n",
            "Epoch: 30/32. Loss: 0.166. Privacy (𝜀,𝛿): (0.5037664555305871, 1e-05)\n",
            "Accuracy of the network on test images: 96.100000 %\n",
            "Test accuracy is 96 %\n",
            "Epoch: 31/32. Loss: 0.164. Privacy (𝜀,𝛿): (0.5123952888452065, 1e-05)\n",
            "Accuracy of the network on test images: 96.120000 %\n",
            "Test accuracy is 96 %\n",
            "Epoch: 32/32. Loss: 0.160. Privacy (𝜀,𝛿): (0.5184525981368759, 1e-05)\n",
            "Accuracy of the network on test images: 96.230000 %\n",
            "Test accuracy is 96 %\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# train and test\n",
        "netS = SimpleConvNet()\n",
        "total_steps = opt.n_epochs * len(trainloader)\n",
        "bayes_accountant = BayesianPrivacyAccountant(powers=[2, 4, 8, 16, 32], total_steps=total_steps)\n",
        "netS, accs = train(trainloader, netS, lr=0.02, n_epochs=opt.n_epochs, accountant=bayes_accountant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJGvl4QBxk-Z",
        "outputId": "4ed583eb-6687-43eb-f9cb-7179808d9c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bayesian DP (𝜀,𝛿):  (0.8782959776431745, 1e-10)\n"
          ]
        }
      ],
      "source": [
        "print(\"Bayesian DP (𝜀,𝛿): \", bayes_accountant.get_privacy(target_delta=1e-10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48yq98i1xk-a"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import pdist\n",
        "\n",
        "sampling_prob = 0.1\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "netS.cuda(gpu_id)\n",
        "loss_fn.cuda(gpu_id)\n",
        "\n",
        "dists_train = []\n",
        "dists_test = []\n",
        "\n",
        "i = 0\n",
        "for inputs, labels in trainloader:\n",
        "    i += 1\n",
        "    if i > 8:\n",
        "        break\n",
        "    inputs = inputs.cuda(gpu_id)\n",
        "    labels = labels.cuda(gpu_id)\n",
        "    netS.zero_grad()\n",
        "    outputs = netS(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    \n",
        "    grads_est = []\n",
        "    num_subbatch = 100\n",
        "    for j in range(num_subbatch):\n",
        "        grad_sample = torch.autograd.grad(loss[np.delete(range(int(opt.batchSize)), j)].mean(), [p for p in netS.parameters() if p.requires_grad], retain_graph=True)\n",
        "        with torch.no_grad():\n",
        "            grad_sample = torch.cat([g.view(-1) for g in grad_sample])\n",
        "            grad_sample /= max(1.0, grad_sample.norm().item() / opt.C)\n",
        "            grads_est += [grad_sample]\n",
        "    with torch.no_grad():\n",
        "        grads_est = torch.stack(grads_est)\n",
        "        sparsify_update(grads_est, p=sampling_prob, use_grad_field=False)\n",
        "    q = opt.batchSize / len(trainloader.dataset)\n",
        "    dists_train += [pdist(grads_est.cpu())]\n",
        "    \n",
        "i = 0\n",
        "for inputs, labels in testloader:\n",
        "    i += 1\n",
        "    if i > 8:\n",
        "        break\n",
        "    inputs = inputs.cuda(gpu_id)\n",
        "    labels = labels.cuda(gpu_id)\n",
        "    netS.zero_grad()\n",
        "    outputs = netS(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    \n",
        "    grads_est = []\n",
        "    num_subbatch = 100\n",
        "    for j in range(num_subbatch):\n",
        "        grad_sample = torch.autograd.grad(loss[np.delete(range(int(opt.batchSize)), j)].mean(), [p for p in netS.parameters() if p.requires_grad], retain_graph=True)\n",
        "        with torch.no_grad():\n",
        "            grad_sample = torch.cat([g.view(-1) for g in grad_sample])\n",
        "            grad_sample /= max(1.0, grad_sample.norm().item() / opt.C)\n",
        "            grads_est += [grad_sample]\n",
        "    with torch.no_grad():\n",
        "        grads_est = torch.stack(grads_est)\n",
        "        sparsify_update(grads_est, p=sampling_prob, use_grad_field=False)\n",
        "    q = opt.batchSize / len(trainloader.dataset)\n",
        "    dists_test += [pdist(grads_est.cpu())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5fZpnOUxk-a",
        "outputId": "855b049b-9f4b-43dd-8466-e069cd67eb9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from scipy.stats import ks_2samp, ttest_rel\n",
        "\n",
        "dists_train = np.stack(dists_train).squeeze()\n",
        "dists_test = np.stack(dists_test).squeeze()\n",
        "\n",
        "plt.hist(dists_train.flatten(), bins=np.arange(0, 0.02, 0.0005), label='Train', alpha=0.5)\n",
        "plt.hist(dists_test.flatten(), bins=np.arange(0, 0.02, 0.0005), label='Test', alpha=0.5)\n",
        "plt.legend()\n",
        "plt.xlabel(r'Distance')\n",
        "plt.ylabel(r'Number of samples')\n",
        "plt.title(r'Pairwise gradient distances distribution, MNIST')\n",
        "plt.savefig('grad_dist_histogram_mnist_2.pdf', format='pdf', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AjKfPcdxk-a",
        "outputId": "4383902d-74a2-41bc-d536-365560c3ddb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TtestResult(statistic=-2.2856676055972476, pvalue=0.022278970451873496, df=39599)\n",
            "Ttest_indResult(statistic=-2.2427026467582456, pvalue=0.024918750414032582)\n",
            "LeveneResult(statistic=20.801336716617335, pvalue=5.10235986310505e-06)\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_rel, ttest_ind, levene\n",
        "\n",
        "print(ttest_rel(dists_train.flatten(), dists_test.flatten()))\n",
        "print(ttest_ind(dists_train.flatten(), dists_test.flatten()))\n",
        "print(levene(dists_train.flatten(), dists_test.flatten()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifIeF7Dhxk-b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}